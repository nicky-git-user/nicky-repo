{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas import Series\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_selection import f_classif, mutual_info_classif\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import auc, roc_auc_score, roc_curve\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.metrics import plot_confusion_matrix\nfrom scipy.stats import kruskal","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/sf-dst-scoring/train.csv')\ntest_df = pd.read_csv('/kaggle/input/sf-dst-scoring/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Заполняем пропуски признака education, используя распределение возможных значений из train выборки"},{"metadata":{"trusted":true},"cell_type":"code","source":"edu_levels = train_df['education'].dropna().unique()\ndistributions = train_df['education'].value_counts(normalize=True)\nmissing_train = train_df['education'].isnull()\ntrain_df.loc[missing_train, 'education'] = np.random.choice(distributions.index, size=len(train_df[missing_train]),p=distributions.values)\nmissing_test = test_df['education'].isnull()\ntest_df.loc[missing_test, 'education'] = np.random.choice(distributions.index, size=len(test_df[missing_test]),p=distributions.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"client_id - идентификатор клиента\n\neducation - уровень образования\n\nsex - пол заемщика\n\nage - возраст заемщика\n\ncar - флаг наличия автомобиля\n\ncar_type - флаг автомобиля иномарки\n\ndecline_app_cnt - количество отказанных прошлых заявок\n\ngood_work - флаг наличия “хорошей” работы\n\nbki_request_cnt - количество запросов в БКИ\n\nhome_address - категоризатор домашнего адреса\n\nwork_address - категоризатор рабочего адреса\n\nincome - доход заемщика\n\nforeign_passport - наличие загранпаспорта\n\nsna - связь заемщика с клиентами банка\n\nfirst_time - давность наличия информации о заемщике\n\nscore_bki - скоринговый балл по данным из БКИ\n\nregion_rating - рейтинг региона\n\napp_date - дата подачи заявки\n\ndefault - флаг дефолта по кредиту"},{"metadata":{},"cell_type":"markdown","source":"Выявляем численные / категориальные факторы"},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in train_df.columns:\n    print(f\"{c} -> {train_df[c].nunique()}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols = ['age', 'income', 'region_rating', 'score_bki']\nbin_cols = ['sex', 'car', 'car_type', 'good_work', 'foreign_passport']\ncat_cols = ['education', 'home_address', 'work_address', 'first_time', 'sna', 'decline_app_cnt', 'bki_request_cnt']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Изучаем распределение численных признаков"},{"metadata":{"trusted":true},"cell_type":"code","source":"rows = len(num_cols) / 2 + 1\nncols = 2\nfig = plt.figure(figsize=(17, 20))\nfor i,c in enumerate(num_cols):\n    ax = fig.add_subplot(rows, ncols, i + 1)\n    train_df[c].hist(ax = ax,bins=100)\n    ax.set_xlabel(c)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"score_bki распределен нормально, остальные численные признаки смещены в разной степени, попробуем нормализовать их"},{"metadata":{"trusted":true},"cell_type":"code","source":"def log_for_col(data):\n    return data.apply(lambda v: np.log(v + 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rows = len(num_cols) / 2 + 1\nncols = 2\nfig = plt.figure(figsize=(17, 20))\nfor i,c in enumerate(num_cols):\n    ax = fig.add_subplot(rows, ncols, i + 1)\n    log_for_col(train_df[c]).hist(ax = ax,bins=100)\n    ax.set_xlabel(c)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Самая значительная корректировка распределения заметна для признака income, применим логарифмирование к его значениям"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['income'] = log_for_col(train_df.income)\ntest_df['income'] = log_for_col(test_df.income)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Оценим сбалансированность классов default == 0 и default == 1 в обучающей выборке"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.default.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Кол-во обучающих примеров плохих заемщиков значительно меньше кол-ва примеров хороших заемщиков. Нужно использовать балансировку классов при построении модели."},{"metadata":{},"cell_type":"markdown","source":"Оценим влияние факторов на целевую переменную"},{"metadata":{"trusted":true},"cell_type":"code","source":"imp_num = Series(f_classif(train_df[num_cols], train_df['default'])[0], index = num_cols)\nimp_num.sort_values(inplace = True)\nimp_num.plot(kind = 'barh')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_encoder = LabelEncoder()\nfor column in bin_cols:\n    train_df[column] = label_encoder.fit_transform(train_df[column])\n    test_df[column] = label_encoder.fit_transform(test_df[column])\ntrain_df['education'] = label_encoder.fit_transform(train_df['education'])\ntest_df['education'] = label_encoder.fit_transform(test_df['education'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imp_cat = Series(mutual_info_classif(train_df[bin_cols + cat_cols], train_df['default'], discrete_features =True), index = bin_cols + cat_cols)\nimp_cat.sort_values(inplace = True)\nimp_cat.plot(kind = 'barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Исследуем взаимное влияние факторов друг на друга"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(20,15))\nsns.heatmap(train_df[num_cols + cat_cols + bin_cols].corr().abs(), vmin=0, vmax=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Заметна связь между уровнем дохода и наличием загран. паспорта, для других численных факторов перекрестных связей не найдено\n* Заметна умеренная связь уровня дохода с наличием и типом транспортного средства, а так же с полом потенциального заемщика\n* Заметна связь между полом заемщика и наличием машины\n* Так же вилим сильную связь между наличием машины и ее типом, что довольно естественно, т.к. если car_type == Y, то и car == Y\n* заметна связь между давностью наличия информации и связью заемщика с клиентами банка\n* заметна сильная связь между метами жительства и работы"},{"metadata":{},"cell_type":"markdown","source":"Преобразуем факторы train датасета - категориальные переменные закодируем с помощью one-hot encoding'а, численные факторы стандартизируем"},{"metadata":{"trusted":true},"cell_type":"code","source":"hot_encoder = OneHotEncoder(sparse = False)\nhot_encoder.fit(pd.concat([train_df[cat_cols], test_df[cat_cols]]).values)\ndef encode_factors(df):\n    X_cat = pd.DataFrame(hot_encoder.transform(df[cat_cols].values))\n    X_num = StandardScaler().fit_transform(df[num_cols].values)\n    X_bin = df[bin_cols].values\n    return np.hstack([X_num, X_bin, X_cat])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = encode_factors(train_df)\nY = train_df['default'].values\nsplitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=100500)\n\ntrain_index, test_index = list(splitter.split(X, Y))[0]\nX_train, X_test = X[train_index], X[test_index]\nY_train, Y_test = Y[train_index], Y[test_index]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Запускаем подбор коэффициента регуляризации и решателя задачи минимизации:\n* коэффициент L2 регуляризации будем выбирать из пространства десятичных логарифмов от 0 до 2\n* будем тестировать: модифицированный метод Ньютона и метод Бройдена-Флетчера-Гольдфарба-Шанно\n\nИспользуем ballanced class_weight и фиксированную отсечку максимального кол-ва итераций обучения в 1000.\nПодбирать будем на 7 разбиениях, оптимизируя f1 score."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n#C=np.linspace(0.01, 50)\nC = np.logspace(0, 2)\nhyperparameters = dict(C=C, penalty=['l2'], solver=['newton-cg','lbfgs'], class_weight=['balanced'], max_iter=[1000])\nmodel = LogisticRegression()\nclf = GridSearchCV(model, hyperparameters, cv=7, verbose=0, scoring='f1')\nbest_model = clf.fit(X_train, Y_train)\nprint('Лучшее C:', best_model.best_estimator_.get_params()['C'])\nprobs = best_model.predict_proba(X_test)\nprobs = probs[:,1]\nfpr, tpr, threshold = roc_curve(Y_test, probs)\nroc_auc = roc_auc_score(Y_test, probs)\nplt.figure()\nplt.plot([0, 1], label='Baseline', linestyle='--')\nplt.plot(fpr, tpr, label = 'Regression')\nplt.title('Logistic Regression ROC AUC = %0.6f' % roc_auc)\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.legend(loc = 'lower right')\nplt.show()\nbest_model.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Оценим confusion matrix для полученной модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(best_model.best_estimator_, X_test, Y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Можно заметить, что модель корректно классифицирует буольшую часть примеров"},{"metadata":{},"cell_type":"markdown","source":"Применим аналогичное кодирование к test датасету и вычислим вероятности невозврата долгов для представленных в нем заемщиков"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_target = encode_factors(test_df)\ntarget_prob = best_model.best_estimator_.predict_proba(X_target)[:,1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Сохраняем результат"},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.concat([test_df.client_id, Series(target_prob, name='default')], axis=1)\nresult.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}
